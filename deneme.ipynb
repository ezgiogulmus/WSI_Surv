{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class DummyDataset(Dataset):\n",
    "\tdef __init__(self, n_bins=4, nb_of_cases=10):\n",
    "\t\tnp.random.seed(7)\n",
    "\t\tself.num_intervals = n_bins\n",
    "\t\tself.path_features =  [torch.randn((i, 1024)) for i in np.random.randint(1, 100, nb_of_cases)]\n",
    "\t\tself.tabular_data = [torch.randn(5)] * nb_of_cases\n",
    "\t\tself.patients_df = pd.DataFrame({\n",
    "\t\t\t\"case_id\": np.arange(1, nb_of_cases+1),\n",
    "\t\t\t\"survival_months\": np.random.randint(1, 100, nb_of_cases),\n",
    "\t\t\t\"event\": np.random.randint(0, 2, nb_of_cases)\n",
    "\t\t})\n",
    "\t\tsurvival_time_list = self.patients_df[\"survival_months\"]\n",
    "\t\t\n",
    "\t\t_, time_breaks = pd.qcut(survival_time_list, q=self.num_intervals, retbins=True, labels=False)\n",
    "\t\ttime_breaks[0] = 0\n",
    "\t\ttime_breaks[-1] += 1\n",
    "\t\tself.time_breaks = time_breaks\n",
    "\t\tprint(\"Time intervals: \", self.time_breaks)\n",
    "\t\tdisc_labels, _ = pd.cut(self.patients_df[\"survival_months\"], bins=self.time_breaks, retbins=True, labels=False, right=False, include_lowest=True)\n",
    "\t\tself.patients_df.insert(2, 'label', disc_labels.values.astype(int))\n",
    "\t\t\n",
    "\t\tself.label_dict = {}\n",
    "\t\tkey_count = 0\n",
    "\t\tfor i in range(len(self.time_breaks)-1):\n",
    "\t\t\tfor c in [0, 1]:\n",
    "\t\t\t\tself.label_dict.update({(i, c):key_count})\n",
    "\t\t\t\tkey_count+=1\n",
    "\n",
    "\t\tself.patients_df.reset_index(drop=True, inplace=True)\n",
    "\t\t\n",
    "\t\tfor i in self.patients_df.index:\n",
    "\t\t\tkey = self.patients_df.loc[i, 'label']\n",
    "\t\t\tself.patients_df.at[i, 'disc_label'] = key\n",
    "\t\t\tevent = self.patients_df.loc[i, 'event']\n",
    "\t\t\tkey = (key, int(event))\n",
    "\t\t\tself.patients_df.at[i, 'label'] = self.label_dict[key]\n",
    "\n",
    "\t\tself.num_classes=len(self.label_dict)\n",
    "\t\tself.summarize()\n",
    "\n",
    "\tdef summarize(self):\n",
    "\t\tprint(\"label column: {}\".format(\"survival_months\"))\n",
    "\t\tprint(\"number of classes: {}\".format(self.num_classes))\n",
    "\t\tfor i in range(self.num_classes):\n",
    "\t\t\tcases = self.patients_df[\"case_id\"][self.patients_df[\"label\"]==i].values\n",
    "\t\t\tnb_cases = len(cases)\n",
    "\t\t\tprint('Number of samples registered in class %d: %d' % (i, nb_cases))\n",
    "\t\t\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.path_features)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tcase_id = self.patients_df['case_id'].iloc[idx]\n",
    "\t\t\n",
    "\t\tt = self.patients_df[\"survival_months\"].iloc[idx]\n",
    "\t\te = self.patients_df['event'].iloc[idx]\n",
    "\t\tlabel = torch.Tensor([self.patients_df['disc_label'][idx]])\n",
    "\t\t\n",
    "\t\treturn self.path_features[idx], label, t, e, self.tabular_data[idx], case_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time intervals:  [  0.    32.5   52.5   77.25 100.  ]\n",
      "label column: survival_months\n",
      "number of classes: 8\n",
      "Number of samples registered in class 0: 10\n",
      "Number of samples registered in class 1: 15\n",
      "Number of samples registered in class 2: 14\n",
      "Number of samples registered in class 3: 11\n",
      "Number of samples registered in class 4: 14\n",
      "Number of samples registered in class 5: 11\n",
      "Number of samples registered in class 6: 13\n",
      "Number of samples registered in class 7: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([48, 1024]), tensor([2.]), 60, 1, torch.Size([5]), 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_bins = 4\n",
    "dataset = DummyDataset(n_bins=n_bins, nb_of_cases=100)\n",
    "data_WSI, y_disc, event_time, event, data_tab, case_id = next(iter(dataset))\n",
    "data_WSI.shape, y_disc, event_time, event, data_tab.shape, case_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([62, 1024]),\n",
       " tensor([0]),\n",
       " tensor([7.]),\n",
       " tensor([1.]),\n",
       " torch.Size([5]),\n",
       " array([60]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_MIL_survival(batch):\n",
    "\timg = torch.cat([item[0] for item in batch], dim = 0)\t\n",
    "\tlabel = torch.cat([item[1] for item in batch], dim = 0).type(torch.LongTensor)\n",
    "\tevent_time = torch.FloatTensor([item[2] for item in batch])\n",
    "\tc = torch.FloatTensor([item[3] for item in batch])\n",
    "\ttabular = torch.cat([item[4] for item in batch], dim = 0).type(torch.FloatTensor)\n",
    "\tcase_id = np.array([item[5] for item in batch])\n",
    "\t\n",
    "\treturn [img, label, event_time, c, tabular, case_id]\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_MIL_survival)\n",
    "data_WSI, y_disc, event_time, event, data_tab, case_id = next(iter(dataloader))\n",
    "data_WSI.shape, y_disc, event_time, event, data_tab.shape, case_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "from utils.loss_func import NLLSurvLoss\n",
    "from models.model_clam import CLAM_SB\n",
    "\n",
    "# SVM loss!\n",
    "instance_loss_fn = nn.CrossEntropyLoss()\n",
    "surv_loss_fn = NLLSurvLoss()\n",
    "# subtyping?\n",
    "model = CLAM_SB(n_classes=n_bins, instance_loss_fn=instance_loss_fn, subtyping=True)\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, Y_prob, Y_hat, _, instance_dict = model(data_WSI, label=y_disc, instance_eval=True, return_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['instance_loss', 'inst_labels', 'inst_preds', 'features'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4]) torch.Size([1, 4]) torch.Size([1]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "hazards = torch.sigmoid(logits)\n",
    "S = torch.cumprod(1 - hazards, dim=1)\n",
    "print(hazards.shape, S.shape, event_time.shape, event.shape)\n",
    "risk = -torch.mean(S, dim=1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_dict = {\n",
    "    'case_id': case_id, \n",
    "    'risk': risk, \n",
    "    'time': event_time.detach().cpu().numpy(), \n",
    "    'event': event.detach().cpu().numpy(),\n",
    "    \"hazards\": np.squeeze(hazards.detach().cpu().numpy()),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "inst_labels = F.one_hot(torch.tensor([0, 1]), num_classes=2).squeeze() #binarize label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 2 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minst_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 2 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "inst_labels[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
